"""åˆ†æJSONæå–ç»“æœä¸­çš„drug_idåœ¨ESä¸­çš„åŒ¹é…æƒ…å†µ"""

import os
import sys
import json
from pathlib import Path
from typing import Set, Dict, List
from collections import defaultdict
from tqdm import tqdm

sys.path.insert(0, str(Path(__file__).parent.parent))

from app.shared import get_es_client, load_env

load_env()

def extract_drug_ids_from_json(json_dir: str) -> Dict[str, Dict]:
    """ä»JSONæ–‡ä»¶ä¸­æå–æ‰€æœ‰drug_idåŠå…¶ç›¸å…³ä¿¡æ¯
    
    Returns:
        Dict[drug_id, {name, extraction_count}]
    """
    json_path = Path(json_dir)
    batch_files = sorted(json_path.glob("batch_*.json"))
    
    print(f"æ‰¾åˆ° {len(batch_files)} ä¸ªæ‰¹æ¬¡æ–‡ä»¶")
    
    drug_info = defaultdict(lambda: {"names": set(), "extraction_count": 0})
    
    for batch_file in tqdm(batch_files, desc="è¯»å–JSONæ–‡ä»¶"):
        try:
            with open(batch_file, 'r', encoding='utf-8') as f:
                batch_data = json.load(f)
            
            extractions = batch_data.get('extractions', [])
            
            for extraction in extractions:
                drug_id = extraction.get('drug_id')
                drug_name = extraction.get('drug_name')
                
                if drug_id:
                    drug_info[drug_id]['names'].add(drug_name)
                    drug_info[drug_id]['extraction_count'] += 1
        
        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶ {batch_file} æ—¶å‡ºé”™: {str(e)}")
            continue
    
    # è½¬æ¢setä¸ºlist
    for drug_id in drug_info:
        drug_info[drug_id]['names'] = list(drug_info[drug_id]['names'])
    
    return dict(drug_info)

def check_ids_in_es(es, drug_ids: Set[str], batch_size: int = 100) -> Dict[str, bool]:
    """æ‰¹é‡æ£€æŸ¥drug_idåœ¨ESä¸­æ˜¯å¦å­˜åœ¨
    
    Returns:
        Dict[drug_id, exists]
    """
    results = {}
    drug_id_list = list(drug_ids)
    
    print(f"\næ£€æŸ¥ {len(drug_id_list)} ä¸ªdrug_idåœ¨ESä¸­çš„å­˜åœ¨æƒ…å†µ...")
    
    for i in tqdm(range(0, len(drug_id_list), batch_size), desc="æ‰¹é‡æŸ¥è¯¢ES"):
        batch_ids = drug_id_list[i:i+batch_size]
        
        # ä½¿ç”¨mgetæ‰¹é‡æŸ¥è¯¢
        try:
            response = es.mget(
                index='drugs',
                body={'ids': batch_ids},
                _source=False
            )
            
            for doc in response['docs']:
                doc_id = doc['_id']
                results[doc_id] = doc['found']
        
        except Exception as e:
            print(f"æ‰¹é‡æŸ¥è¯¢å‡ºé”™: {str(e)}")
            # é™çº§ä¸ºå•ä¸ªæŸ¥è¯¢
            for drug_id in batch_ids:
                try:
                    exists = es.exists(index='drugs', id=drug_id)
                    results[drug_id] = exists
                except:
                    results[drug_id] = False
    
    return results

def check_names_in_es(es, drug_names: Set[str]) -> Dict[str, int]:
    """æ£€æŸ¥drug_nameåœ¨ESä¸­çš„åŒ¹é…æ•°é‡
    
    Returns:
        Dict[drug_name, match_count]
    """
    results = {}
    
    print(f"\næ£€æŸ¥ {len(drug_names)} ä¸ªè¯å“åç§°åœ¨ESä¸­çš„åŒ¹é…æƒ…å†µ...")
    
    for drug_name in tqdm(drug_names, desc="æŒ‰åç§°æŸ¥è¯¢"):
        try:
            response = es.count(
                index='drugs',
                body={
                    "query": {"match": {"name": drug_name}}
                }
            )
            results[drug_name] = response['count']
        except Exception as e:
            results[drug_name] = 0
    
    return results

def generate_report(drug_info: Dict, id_matching: Dict, name_matching: Dict):
    """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
    
    print("\n" + "=" * 80)
    print("åŒ¹é…åˆ†ææŠ¥å‘Š")
    print("=" * 80)
    
    # ç»Ÿè®¡åŸºæœ¬ä¿¡æ¯
    total_drugs = len(drug_info)
    total_extractions = sum(info['extraction_count'] for info in drug_info.values())
    
    print(f"\nã€åŸºæœ¬ä¿¡æ¯ã€‘")
    print(f"  JSONä¸­çš„å”¯ä¸€drug_idæ•°: {total_drugs}")
    print(f"  æ€»æå–è®°å½•æ•°: {total_extractions}")
    
    # IDåŒ¹é…ç»Ÿè®¡
    matched_ids = sum(1 for exists in id_matching.values() if exists)
    unmatched_ids = total_drugs - matched_ids
    match_rate = (matched_ids / total_drugs * 100) if total_drugs > 0 else 0
    
    print(f"\nã€IDåŒ¹é…æƒ…å†µã€‘")
    print(f"  ESä¸­å­˜åœ¨çš„ID: {matched_ids} ({match_rate:.2f}%)")
    print(f"  ESä¸­ä¸å­˜åœ¨çš„ID: {unmatched_ids} ({100-match_rate:.2f}%)")
    
    # åç§°åŒ¹é…ç»Ÿè®¡
    all_names = set()
    for info in drug_info.values():
        all_names.update(info['names'])
    
    names_with_matches = sum(1 for count in name_matching.values() if count > 0)
    names_without_matches = len(name_matching) - names_with_matches
    
    print(f"\nã€åç§°åŒ¹é…æƒ…å†µã€‘")
    print(f"  å”¯ä¸€è¯å“åç§°æ•°: {len(all_names)}")
    print(f"  èƒ½åœ¨ESä¸­æ‰¾åˆ°çš„åç§°: {names_with_matches}")
    print(f"  ESä¸­æ‰¾ä¸åˆ°çš„åç§°: {names_without_matches}")
    
    # è¯¦ç»†ç»Ÿè®¡
    total_name_matches = sum(name_matching.values())
    avg_matches_per_name = total_name_matches / len(name_matching) if name_matching else 0
    
    print(f"  ESä¸­æ€»åŒ¹é…è®°å½•æ•°: {total_name_matches}")
    print(f"  å¹³å‡æ¯ä¸ªåç§°åŒ¹é…æ•°: {avg_matches_per_name:.1f}")
    
    # åˆ†æä¸åŒ¹é…çš„è¯å“
    print(f"\nã€ä¸åŒ¹é…è¯å“åˆ†æã€‘")
    
    unmatched_drugs = []
    for drug_id, info in drug_info.items():
        if not id_matching.get(drug_id, False):
            # æ£€æŸ¥åç§°æ˜¯å¦èƒ½åŒ¹é…
            name_match_counts = [name_matching.get(name, 0) for name in info['names']]
            total_name_matches = sum(name_match_counts)
            
            unmatched_drugs.append({
                'drug_id': drug_id,
                'names': info['names'],
                'extraction_count': info['extraction_count'],
                'name_matches': total_name_matches
            })
    
    # æŒ‰æå–æ¬¡æ•°æ’åº
    unmatched_drugs.sort(key=lambda x: x['extraction_count'], reverse=True)
    
    # ç»Ÿè®¡æœ‰å¤šå°‘ä¸åŒ¹é…çš„IDä½†åç§°èƒ½åŒ¹é…ä¸Š
    name_recoverable = sum(1 for d in unmatched_drugs if d['name_matches'] > 0)
    
    if unmatched_ids > 0:
        print(f"  IDä¸åŒ¹é…ä½†åç§°å¯åŒ¹é…: {name_recoverable} ({name_recoverable/unmatched_ids*100:.1f}%)")
        print(f"  IDå’Œåç§°éƒ½ä¸åŒ¹é…: {unmatched_ids - name_recoverable}")
    else:
        print(f"  âœ… æ‰€æœ‰IDéƒ½èƒ½åœ¨ESä¸­åŒ¹é…ï¼")
    
    # å±•ç¤ºå‰10ä¸ªé«˜é¢‘ä¸åŒ¹é…è¯å“
    print(f"\nã€å‰10ä¸ªé«˜é¢‘ä¸åŒ¹é…è¯å“ã€‘")
    for i, drug in enumerate(unmatched_drugs[:10], 1):
        print(f"\n  {i}. {', '.join(drug['names'])}")
        print(f"     ID: {drug['drug_id']}")
        print(f"     æå–æ¬¡æ•°: {drug['extraction_count']}")
        print(f"     åç§°åœ¨ESä¸­çš„åŒ¹é…æ•°: {drug['name_matches']}")
    
    # ç»“è®º
    print(f"\n" + "=" * 80)
    print("ã€ç»“è®ºã€‘")
    print("=" * 80)
    
    if match_rate > 90:
        print("âœ… IDåŒ¹é…ç‡å¾ˆé«˜ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨IDæ›´æ–°")
    elif match_rate > 50:
        print("âš ï¸  IDåŒ¹é…ç‡ä¸­ç­‰ï¼Œå»ºè®®ç»“åˆåç§°åŒ¹é…")
    else:
        print("âŒ IDåŒ¹é…ç‡ä½ï¼Œå»ºè®®ä½¿ç”¨åç§°åŒ¹é…ç­–ç•¥")
    
    if name_recoverable > unmatched_ids * 0.8:
        print("âœ… å¤§éƒ¨åˆ†ä¸åŒ¹é…IDå¯ä»¥é€šè¿‡åç§°æ¢å¤")
        print("ğŸ’¡ å»ºè®®ï¼šä¿®æ”¹æ›´æ–°è„šæœ¬ï¼Œä½¿ç”¨åç§°åŒ¹é…ç­–ç•¥")
    else:
        print("âš ï¸  å¾ˆå¤šè¯å“åç§°ä¹Ÿæ— æ³•åŒ¹é…ï¼Œå¯èƒ½æ˜¯ä¸åŒçš„æ•°æ®æ¥æº")
    
    return {
        'total_drugs': total_drugs,
        'matched_ids': matched_ids,
        'unmatched_ids': unmatched_ids,
        'match_rate': match_rate,
        'name_recoverable': name_recoverable,
        'unmatched_drugs': unmatched_drugs
    }

def save_detailed_report(report_data: Dict, output_file: str = "data/cache/drug_id_matching_report.json"):
    """ä¿å­˜è¯¦ç»†æŠ¥å‘Š"""
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")

def main():
    es = get_es_client()
    json_dir = "data/processed/diseases/diseases_search_after"
    
    # 1. æå–drug_id
    drug_info = extract_drug_ids_from_json(json_dir)
    
    # 2. æ£€æŸ¥IDåŒ¹é…
    drug_ids = set(drug_info.keys())
    id_matching = check_ids_in_es(es, drug_ids)
    
    # 3. æ£€æŸ¥åç§°åŒ¹é…
    all_names = set()
    for info in drug_info.values():
        all_names.update(info['names'])
    name_matching = check_names_in_es(es, all_names)
    
    # 4. ç”ŸæˆæŠ¥å‘Š
    report_data = generate_report(drug_info, id_matching, name_matching)
    
    # 5. ä¿å­˜è¯¦ç»†æ•°æ®
    detailed_data = {
        'drug_info': {k: dict(v) for k, v in drug_info.items()},
        'id_matching': id_matching,
        'name_matching': name_matching,
        'summary': {
            'total_drugs': report_data['total_drugs'],
            'matched_ids': report_data['matched_ids'],
            'unmatched_ids': report_data['unmatched_ids'],
            'match_rate': report_data['match_rate'],
            'name_recoverable': report_data['name_recoverable']
        }
    }
    save_detailed_report(detailed_data)

if __name__ == "__main__":
    main()
